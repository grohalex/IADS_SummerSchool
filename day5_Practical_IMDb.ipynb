{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "day5-Practical_IMDb.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grohalex/IADS_SummerSchool/blob/main/day5_Practical_IMDb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oya4B5xeEyK"
      },
      "source": [
        "!pip install shap\n",
        "!pip3 install lime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXzP9HCr6P90"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from shap.datasets import imdb\n",
        "\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import GlobalAveragePooling1D\n",
        "from keras.layers import Dense\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from lime import lime_text\n",
        "from lime.lime_text import LimeTextExplainer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ch__pLX86ROS"
      },
      "source": [
        "data, y = imdb()\n",
        "\n",
        "vocab_size = 10000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aorahJtH6cam"
      },
      "source": [
        "# TODO: use one_hot function from Keras\u000bto convert the text to a one-hot encoding\u000b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oy0GJKwl6qw_"
      },
      "source": [
        "# TODO: use pad_sequences function from Keras\u000bto pad the sequences so they have the same length\u000b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIAVAyp760G1"
      },
      "source": [
        "labels = [1 if target == True else 0 for target in y]\n",
        "labels = to_categorical(np.asarray(labels).astype(int), 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJJDYEov6vID"
      },
      "source": [
        "# TODO: split the dataset into training and testing sets\u000b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEwQ5uWE6v4s"
      },
      "source": [
        "# TODO: implement a Sequential model \n",
        "# use an Embedding layer and GlobalAveragePooling1D\n",
        "# use softmax in your last layer\n",
        "# use categorical cross-entropy as your loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3SYl13f7IKM"
      },
      "source": [
        "# TODO: train the model for 50 epochs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNaQFUOs7TdT"
      },
      "source": [
        "def new_predict(texts):\n",
        "  _seq = [one_hot(d, vocab_size) for d in texts]\n",
        "  _text_data = pad_sequences(_seq, maxlen=256)\n",
        "  return model.predict(_text_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASUYfoPA7T4h"
      },
      "source": [
        "# TODO: use LimeTextExplainer to explain the prediction of the instance\u000b"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}